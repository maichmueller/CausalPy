{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/GitHub/CausalPy/causalpy/causal_prediction/interventional/agnostic.py:329: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert (\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "from functools import partial\n",
    "from typing import Union, Collection, Optional\n",
    "\n",
    "import visdom\n",
    "import torch\n",
    "from torch.nn import Parameter, Module\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import math\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from causalpy import SCM, LinearAssignment, NoiseGenerator, DiscreteNoise\n",
    "from causalpy.neural_networks import cINN, L0InputGate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from examples.simulation_linear import simulate\n",
    "from causalpy.causal_prediction.interventional import ICPredictor, AgnosticPredictor\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from scipy.stats import wasserstein_distance\n",
    "from plotly import graph_objs as go\n",
    "from build_scm_funcs import *\n",
    "from linear_regression_eval import *\n",
    "\n",
    "\n",
    "import torch as th\n",
    "import math\n",
    "from torch.utils.data import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 1: Intervention on variable X_0 for value 0.\n",
      "Environment 2: Intervention on variable X_1 for value 0.\n",
      "Environment 3: Intervention on variable X_2 for value 0.\n",
      "Environment 4: Intervention on variable X_3 for value 0.\n",
      "Environment 5: Intervention on variable X_4 for value 0.\n",
      "Environment 6: Intervention on variable X_5 for value 0.\n",
      "Structural Causal Model of 7 variables: X_0, X_1, X_2, X_3, Y, X_4, X_5\n",
      "Following variables are actively intervened on: []\n",
      "Current Assignment Functions are:\n",
      "X_0 := f(N) = 1 N\t [ N := Normal(loc=0, scale=1) ]\n",
      "X_1 := f(N, X_0) = 1 + 1 N + 1 X_0\t [ N := Normal(loc=0, scale=1) ]\n",
      "X_2 := f(N, X_0, X_1) = 1 + 1 N + 0.8 X_0 + -1.2 X_1\t [ N := Normal(loc=0, scale=1) ]\n",
      "X_3 := f(N, X_1, X_2) = 1 N + 0.3 X_1 + 0.4 X_2\t [ N := Normal(loc=0, scale=1) ]\n",
      "  Y := f(N, X_3, X_0) = 0.6 + 1 N + 1 X_3 + -1 X_0\t [ N := Normal(loc=0, scale=1) ]\n",
      "X_4 := f(N, Y) = 1.2 + 1 N + -0.7 Y\t [ N := Normal(loc=0, scale=1) ]\n",
      "X_5 := f(N, X_3, Y) = 0.5 + 1 N + -0.7 X_3 + 0.4 Y\t [ N := Normal(loc=0, scale=1) ]\n",
      "Target Variable: Y\n",
      "Actual Parents: X_0, X_3\n",
      "Candidate Parents: X_0, X_1, X_2, X_3, X_4, X_5\n",
      "Sample size: 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d3cad46c7446679fcd0f300ed89a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c659756bb9e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize_with_visdom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_visdom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         )\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplete_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbeta_star\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0massignment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/CausalPy/causalpy/causal_prediction/interventional/agnostic.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, obs, envs, target_variable, show_epoch_progressbar, ground_truth_mask)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0menv_batch_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_indices_by_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 env_loss, env_samples = self._compute_environmental_loss(\n\u001b[0;32m--> 233\u001b[0;31m                     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_batch_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_visdom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m                 )\n\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# env_loss = self._compute_overall_gaussian_loss(gauss_sample)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/CausalPy/causalpy/causal_prediction/interventional/agnostic.py\u001b[0m in \u001b[0;36m_compute_environmental_loss\u001b[0;34m(self, obs, target, batch_indices_by_env, mask, save_samples)\u001b[0m\n\u001b[1;32m    428\u001b[0m                     \u001b[0;31m# target marginal distribution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                     \u001b[0mloss_per_mask\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mwasserstein\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                     \u001b[0mloss_per_mask\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmmd_multiscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m                     \u001b[0mloss_per_mask\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmoments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0menv_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_per_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/CausalPy/causalpy/neural_networks/utils.py\u001b[0m in \u001b[0;36mmmd_multiscale\u001b[0;34m(x, y, normalize_j)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mrx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "beta_star = None\n",
    "scm_generator, target_var = build_scm_medium, \"Y\"\n",
    "for sample_size in [30, 60, 90, 120, 200, 300, 600, 900, 1000, 1100, 1200, 1300, 1400, 1500, 3000]:\n",
    "# (build_scm_large, \"Y\"),\n",
    "# (partial(simulate, nr_genes=15), \"G_12\"),\n",
    "# (partial(simulate, nr_genes=20), \"G_16\"),\n",
    "# (partial(simulate, nr_genes=25), \"G_21\"),\n",
    "# (partial(simulate, nr_genes=30), \"G_29\"),\n",
    "    nr_repetitions = 20\n",
    "    for rep in range(nr_repetitions):\n",
    "        (\n",
    "            complete_data,\n",
    "            environments,\n",
    "            scm,\n",
    "            possible_parents,\n",
    "            target_parents,\n",
    "        ) = generate_data_from_scm(\n",
    "            scm=scm_generator(seed=seed),\n",
    "            markovblanket_interv_only=False,\n",
    "            target_var=target_var,\n",
    "            sample_size=sample_size,\n",
    "            seed=seed,\n",
    "        )\n",
    "        target_parents_indices = np.array(\n",
    "            [possible_parents.index(par) for par in target_parents]\n",
    "        )\n",
    "        nr_envs = np.unique(environments).max() + 1\n",
    "\n",
    "        results = []\n",
    "        epochs = 300\n",
    "        use_visdom = False\n",
    "        # for _ in range(nr_repetitions):\n",
    "        print(\"Sample size:\", sample_size)\n",
    "        ap = AgnosticPredictor(\n",
    "            epochs=epochs, batch_size=1000, visualize_with_visdom=use_visdom\n",
    "        )\n",
    "        results.append(ap.infer(complete_data, environments, target_var,))\n",
    "        if beta_star is None:\n",
    "            assignment = scm[target_var][1][scm.function_key]\n",
    "            beta_star = np.array([assignment.offset] + assignment.coefficients.tolist())\n",
    "        print(results[-1])\n",
    "        (res_hat, beta_hat), _, y_hat = evaluate(\n",
    "            complete_data,\n",
    "            ap,\n",
    "            environments,\n",
    "            ground_truth_assignment=scm[target_var][1][scm.function_key],\n",
    "            x_vars=target_parents,\n",
    "            targ_var=target_var,\n",
    "            plot=False\n",
    "        )\n",
    "        betas.append(beta_hat)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:causalpy] *",
   "language": "python",
   "name": "conda-env-causalpy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
